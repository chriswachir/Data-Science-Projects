---
title: "Prediction of Loan Defaulters"
author: "sammy waiyaki"
date: "17/10/2019"
output: pdf_document
---
## importing data
importation of bank data set for analysis
```{r}
bank_data <- read.csv(file.choose(), header = T)
View(bank_data)
attach(bank_data)
```

### exploration on the data
```{r}
str(bank_data)
dim(bank_data)
Na_table <- table(is.na(bank_data))
Na_table
```
### summary statistics on the data
```{r}
summary(bank_data)
```
## let us drop unwanted columns
we use dplyr which is a data wrangling package in r
```{r}
library(dplyr)
bank_data1 <-select(bank_data, -c(1,2,3,4))
View(bank_data1)
```
## Exploratory data analysis using visualizations
This is important for drawing insights from the data
ggplot library is of essence to produce nice visualizations
```{r}
library(ggplot2)
```
## A quick look on the distribution of the defaul which is our our target variable.

We can see that the number of non defaulters (Yes) is greater that defaulters(No)
```{r}
ggplot(data = bank_data1) +
  geom_bar(aes(x = default))
```
## distribution of eduation level with target variable
We can see that people with high school degree defaulted than those with post-graduate degree
```{r}
ggplot(bank_data1, aes(eduction_level, ..count..)) + geom_bar(aes(fill = default), position = "dodge")
```
## Age groups to visualize their loan repayment behavior
we can see that people with less than 26 years defaulted more than those with advance ages
```{r}
bins <- c(0,25,30,40,50,60)
age_cat <- c('<=26','26-30','30-40','40-50','50+')
bank_data1$age_bin <- cut(age, labels = age_cat, breaks = bins)

ggplot(bank_data1, aes(age_bin, ..count..)) + geom_bar(aes(fill = default), position = "dodge")
```
## creating income categories to visualize their loan repayment behavior
we can see that people under the income category of low income defaulted the most than those in other categories
```{r}
income_bins = c(0,25,50,153)
income_cat <- c('low income', 'average income', 'high income')
bank_data1$income_category <-  cut(income, labels = income_cat, breaks = income_bins)

ggplot(bank_data1, aes(income_category, ..count..)) + geom_bar(aes(fill = default), position = "dodge")
```
## Distribution of numerical variables
## Histograms to visualize distributions of age and income
```{r}
qplot(age, geom = "histogram", main = 'histogram of Age')
qplot(income, geom = 'histogram', main = 'histogram of income')
```
## box plots of income and age brouped by default status
we can see that people with low mean age defaulted than those with high mean age. The same applies to income.
```{r}
boxplot(age ~ default, main='box plot of age with target variable defaut', las = 1)
boxplot(income ~ default, main='box plot of income and target variable default', las=1)
```
##### droping the age and income bins created for visualization purposes
```{r}
bank_data2<- select(bank_data1, -c(10, 11))
View(bank_data2)
```
## building logistic regression model to predict defaulters
Logistic regression is a classification algorithm for dichotomous vaiable or binary such as 'Yes' and 'No' or '0' and '1'
libraries such as caret are very fundamental in building predictive machine learning model
```{r}
library(caret)
library(klaR)
```
#### creating traning and testing data sets
train set enables the algorithm learn about patterns within data while the testing set is used to evaluate perfomance of the model in classifying the defaulters and non-defaulters
```{r}
trainIndex <- createDataPartition(bank_data2$default, p=0.80, list=FALSE)
train_set <- bank_data2[ trainIndex,]
test_set <- bank_data2[-trainIndex,]
```
#### train logistic regression using training set and summary of the model
```{r}
fit <- glm(default~., data=train_set, family = binomial(link = 'logit'))
summary(fit)
```
#### make predictions based on the test set and visualizing classified classes using confusion matrix
```{r}
probabilities <- predict(fit, test_set[,1:8,], type = 'response')
predictions <- ifelse(probabilities > 0.5,'Yes','No')
# summarize results
table2 <- table(predictions, test_set$default)
table2
```
#### accuracy of the logistic_modelprediction
The model predicted 74.44% default classes accurately.
```{r}
accuracy <- (127+39)/(127+39+42+15)
accuracy
```
